{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, time, pandas\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = None # This variable holds the value of the first frame\n",
    "status_list = [None,None] # This variable holds the list of statuses - if Python has come across a frame greater than 1000 pixels\n",
    "times = [] # This variable holds the timestamps during which a motion that was detected started and ended\n",
    "df = pandas.DataFrame(columns = [\"Start\",\"End\"]) # The dataframe that will hold the timestamp for each detected motion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0) # To capture the video from the first camera of the device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    check, frame = vid.read() # To read frame by frame\n",
    "    status = 0\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)# To convert the image to grayscale\n",
    "    gray_frame = cv2.GaussianBlur(gray_frame,(21,21),0) # To make the image blurry so that noise is reduced and accuracy is improved\n",
    "    \n",
    "    if first is None:\n",
    "        first = gray_frame\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    diff = cv2.absdiff(first, gray_frame) # To compute and store the absolute difference between the frames\n",
    "    thresh_diff = cv2.threshold(diff,30,255,cv2.THRESH_BINARY)[1] # To convert differences less than 30 as WHITE and more than 30 as BLACK\n",
    "    thresh_diff = cv2.dilate(thresh_diff,None,iterations = 2) # To increase the object area\n",
    "    (_,cnts,_) = cv2.findContours(thresh_diff.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE) # To find the contours of the frame\n",
    "    \n",
    "    \n",
    "    for contour in cnts: # To iterate through the contours\n",
    "        if cv2.contourArea(contour) < 1000: # To check if the contour area is less than 1000 pixels\n",
    "            continue\n",
    "        status = 1 # To remember that Python has found a frame that is bigger than 1000px\n",
    "        (x,y,w,h)= cv2.boundingRect(contour) # To find the rectangle bounding the contours\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3) # To draw a rectangle around the object\n",
    "        \n",
    "    status_list.append(status)\n",
    "    if status_list[-1] == 1 and status_list[-2] == 0: # To figure out the start time\n",
    "        times.append(datetime.now()) # To store the start time\n",
    "    if status_list[-1] == 0 and status_list[-2] == 1: # To figure out the end tome\n",
    "        times.append(datetime.now()) # To store the end time\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"Gray\",gray_frame) # To display the frames that are captured in gray scale\n",
    "    cv2.imshow(\"Difference\",diff) # To display the difference between the frames\n",
    "    cv2.imshow(\"Threshold\",thresh_diff) # To display the difference after the threshold has been applied\n",
    "    cv2.imshow(\"Color\",frame) # To display the original color frames\n",
    "    \n",
    "    key = cv2.waitKey(1) # To wait till a key is pressed\n",
    "    \n",
    "    if key == ord('q'): # To quit if the key pressed is q\n",
    "        if status == 1:\n",
    "            times.append(datetime.now())\n",
    "        break\n",
    "        \n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write the timestamps to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(times),2):\n",
    "    df=df.append({\"Start\":times[i],\"End\":times[i+1]},ignore_index=True) # To store the start and end times of when each motion was detected\n",
    "\n",
    "df.to_csv(\"Times.csv\") # To write to the Times.csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End the video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid.release() # To stop the capturing device from capturing video\n",
    "cv2.destroyAllWindows # To close the windows and deallocate associated memory usage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
